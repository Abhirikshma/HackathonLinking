{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "35611454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.1'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import awkward as ak\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch_geometric\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import EdgeConv\n",
    "from torch_geometric.data import Data, Dataset, HeteroData\n",
    "from torch_geometric.loader import DataLoader\n",
    "#from torch_geometric.graphgym import params_count\n",
    "import torch_geometric.utils as Utils\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import mplhep as hep\n",
    "\n",
    "plt.style.use(hep.style.CMS)\n",
    "torch_geometric.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86753259",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ef7b7274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Loading Files ...\n",
      "===== Loaded! \n"
     ]
    }
   ],
   "source": [
    "print(\"===== Loading Files ...\")\n",
    "trainData = \"./dataProcessed/dataTraining.pt\"\n",
    "layData = './dataProcessed/dataTrainingLay.pt'\n",
    "valData = \"./dataProcessed/dataVal.pt\"\n",
    "testData = \"./dataProcessed/dataTest.pt\"\n",
    "trainDatasetLay = torch.load(layData)\n",
    "trainDataset = torch.load(trainData)\n",
    "valDataset = torch.load(valData)\n",
    "testDataset = torch.load(testData)\n",
    "print(\"===== Loaded! \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "26c84298",
   "metadata": {},
   "outputs": [],
   "source": [
    "def focal_loss(bce_loss, targets, gamma, alpha):\n",
    "    \"\"\"Binary focal loss, mean.\n",
    "\n",
    "    Per https://discuss.pytorch.org/t/is-this-a-correct-implementation-for-focal-loss-in-pytorch/43327/5 with\n",
    "    improvements for alpha.\n",
    "    :param bce_loss: Binary Cross Entropy loss, a torch tensor.\n",
    "    :param targets: a torch tensor containing the ground truth, 0s and 1s.\n",
    "    :param gamma: focal loss power parameter, a float scalar.\n",
    "    :param alpha: weight of the class indicated by 1, a float scalar.\n",
    "    \"\"\"\n",
    "    p_t = torch.exp(-bce_loss)\n",
    "    alpha_tensor = (1 - alpha) + targets * (2 * alpha - 1)  # alpha if target = 1 and 1 - alpha if target = 0\n",
    "    f_loss = alpha_tensor * (1 - p_t) ** gamma * bce_loss\n",
    "    return f_loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6f8d661a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self,num_filters=4, out_features=2):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(1, num_filters, 3, stride=1, dilation=1)\n",
    "        self.conv2 = nn.Conv1d(num_filters, 2*out_features, 3, stride = 3)\n",
    "        self.conv3 = nn.Conv1d(2*out_features, 2*out_features, 3, stride = 3)\n",
    "        self.conv4 = nn.Conv1d(2*out_features, 2*2*out_features, 3, stride = 3)\n",
    "        self.pool = nn.MaxPool1d(1)\n",
    "#         self.pool = nn.AvgPool1d(1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.pool(x)\n",
    "        x = torch.reshape(x, (x.shape[0], x.shape[1]))\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "class GraphNet(nn.Module):\n",
    "    def __init__(self, input_dim = 12, hidden_dim = 128, output_dim = 1, aggr = 'add', niters = 4):\n",
    "        super(GraphNet, self).__init__()\n",
    "        self.featureExtractor = Net()\n",
    "        \n",
    "        # transform to latent space\n",
    "        self.inputnetwork = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ELU(),\n",
    "#             nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "#             nn.Dropout(0.2),\n",
    "#             nn.Linear(2*hidden_dim, hidden_dim),\n",
    "#             nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # to compute messages\n",
    "        convnetwork = nn.Sequential(\n",
    "            nn.Linear(2 * hidden_dim, 2 * hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(2 * hidden_dim, hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # EdgeConv\n",
    "        self.graphconv = EdgeConv(nn=convnetwork, aggr=aggr)\n",
    "        \n",
    "        # edge features from node embeddings for classification\n",
    "        self.edgenetwork = nn.Sequential(\n",
    "            nn.Linear(2 * hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(hidden_dim, output_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        self.niters = niters\n",
    "    \n",
    "    def forward(self, data, device = \"cuda\"):\n",
    "        X = data.x\n",
    "        en_lay = data.en_hgcal_layers\n",
    "#         print(en_lay.shape)\n",
    "        en_lay = en_lay.cpu()\n",
    "#         print(en_lay.shape)\n",
    "        en_lay_in = torch.reshape(torch.from_numpy(np.float32(en_lay)), (en_lay.shape[0],1,en_lay.shape[1]))\n",
    "#         print(en_lay_in.shape)\n",
    "        \n",
    "        if(device == 'cuda'):\n",
    "            en_lay_in = en_lay_in.cuda()\n",
    "        \n",
    "#         features = self.featureExtractor(en_lay_in)\n",
    "        #print(f\"initial X size {X.size()}\")\n",
    "#         X = torch.cat([X, features], dim = -1)\n",
    "        H = self.inputnetwork(X)\n",
    "        #print(f\"size after inputnet {H.size()}\")\n",
    "        for i in range(self.niters):\n",
    "            (prepared_edges, _) = Utils.add_self_loops(data.edge_index)\n",
    "            H = self.graphconv(H, Utils.to_undirected(prepared_edges))\n",
    "            #print(f\"size of H after {i}th iter {H.size()}\")\n",
    "            \n",
    "        src, dst = data.edge_index\n",
    "        #print(f\"src size {H[src].size()} dest size {H[dst].size()}\")\n",
    "        #print(f\"torch cat {torch.cat([H[src], H[dst]], dim=-1).size()}\")\n",
    "        #print(f\"GraphNet returns {self.edgenetwork(torch.cat([H[src], H[dst]], dim=-1)).squeeze(-1).size()}\")\n",
    "        #print(f\"score size {(H[src] * H[dst]).sum(dim=-1)}\")\n",
    "        #return (H[src] * H[dst]).sum(dim=-1)\n",
    "        return self.edgenetwork(torch.cat([H[src], H[dst]], dim=-1)).squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "85f923d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total edges in training : 10639134\n",
      "True edges : 6527329\n",
      "False edges : 4111805\n"
     ]
    }
   ],
   "source": [
    "# Imbalance in training\n",
    "train_edges_total = 0\n",
    "train_edges_true = 0\n",
    "train_edges_false = 0\n",
    "\n",
    "for tr_data in trainDataset:\n",
    "    train_edges_total += len(tr_data.edge_index[0])\n",
    "    for label in tr_data.edge_label:\n",
    "        if label.numpy() == 0:\n",
    "            train_edges_false += 1\n",
    "        elif label.numpy() == 1:\n",
    "            train_edges_true += 1\n",
    "        \n",
    "print(f\"Total edges in training : {train_edges_total}\")\n",
    "print(f\"True edges : {train_edges_true}\")\n",
    "print(f\"False edges : {train_edges_false}\")\n",
    "\n",
    "# # edges in test dataset\n",
    "# test_edges_total = 0\n",
    "# test_edges_true = 0\n",
    "# test_edges_false = 0\n",
    "# for test_data in testDataset:\n",
    "#     test_edges_total += len(test_data.edge_index[0])\n",
    "#     for label in test_data.edge_label:\n",
    "#         if label.numpy() == 0:\n",
    "#             test_edges_false += 1\n",
    "#         elif label.numpy() == 1:\n",
    "#             test_edges_true += 1\n",
    "            \n",
    "# print(f\"\\nTotal edges in test : {test_edges_total}\")\n",
    "# print(f\"True edges : {test_edges_true} - {test_edges_true/test_edges_total*100}%\")\n",
    "# print(f\"False edges : {test_edges_false} - {test_edges_false/test_edges_total*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "be17f0b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights True, False edges : 0.8149684197012285, 1.29373036902285\n"
     ]
    }
   ],
   "source": [
    "# Calculate weights\n",
    "w_false = train_edges_total/(2*train_edges_false)\n",
    "w_true = train_edges_total/(2*train_edges_true)\n",
    "print(f\"Weights True, False edges : {w_true}, {w_false}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b868de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6e7a7a8f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.0001\n",
      "epoch 0 - train loss 0.1228 - val loss 0.0744\n",
      "lr: 0.0001\n",
      "epoch 1 - train loss 0.0730 - val loss 0.0715\n",
      "lr: 0.0001\n",
      "epoch 2 - train loss 0.0703 - val loss 0.0685\n",
      "lr: 0.0001\n",
      "epoch 3 - train loss 0.0670 - val loss 0.0640\n",
      "lr: 0.0001\n",
      "epoch 4 - train loss 0.0630 - val loss 0.0613\n",
      "lr: 0.0001\n",
      "epoch 5 - train loss 0.0604 - val loss 0.0592\n",
      "lr: 0.0001\n",
      "epoch 6 - train loss 0.0585 - val loss 0.0579\n",
      "lr: 0.0001\n",
      "epoch 7 - train loss 0.0566 - val loss 0.0564\n",
      "lr: 0.0001\n",
      "epoch 8 - train loss 0.0554 - val loss 0.0549\n",
      "lr: 0.0001\n",
      "epoch 9 - train loss 0.0545 - val loss 0.0541\n",
      "lr: 0.0001\n",
      "epoch 10 - train loss 0.0538 - val loss 0.0535\n",
      "lr: 0.0001\n",
      "epoch 11 - train loss 0.0533 - val loss 0.0530\n",
      "lr: 0.0001\n",
      "epoch 12 - train loss 0.0529 - val loss 0.0528\n",
      "lr: 0.0001\n",
      "epoch 13 - train loss 0.0526 - val loss 0.0525\n",
      "lr: 0.0001\n",
      "epoch 14 - train loss 0.0523 - val loss 0.0525\n",
      "lr: 0.0001\n",
      "epoch 15 - train loss 0.0521 - val loss 0.0521\n",
      "lr: 0.0001\n",
      "epoch 16 - train loss 0.0520 - val loss 0.0518\n",
      "lr: 0.0001\n",
      "epoch 17 - train loss 0.0518 - val loss 0.0516\n",
      "lr: 0.0001\n",
      "epoch 18 - train loss 0.0516 - val loss 0.0516\n",
      "lr: 0.0001\n",
      "epoch 19 - train loss 0.0515 - val loss 0.0515\n",
      "lr: 0.0001\n",
      "epoch 20 - train loss 0.0513 - val loss 0.0514\n",
      "lr: 0.0001\n",
      "epoch 21 - train loss 0.0513 - val loss 0.0514\n",
      "lr: 0.0001\n",
      "epoch 22 - train loss 0.0512 - val loss 0.0513\n",
      "lr: 0.0001\n",
      "epoch 27 - train loss 0.0508 - val loss 0.0508\n",
      "lr: 0.0001\n",
      "epoch 28 - train loss 0.0508 - val loss 0.0508\n",
      "lr: 0.0001\n",
      "epoch 29 - train loss 0.0507 - val loss 0.0506\n",
      "lr: 0.0001\n",
      "epoch 30 - train loss 0.0506 - val loss 0.0507\n",
      "lr: 0.0001\n",
      "epoch 31 - train loss 0.0506 - val loss 0.0507\n",
      "lr: 0.0001\n",
      "epoch 32 - train loss 0.0505 - val loss 0.0509\n",
      "lr: 0.0001\n",
      "epoch 33 - train loss 0.0505 - val loss 0.0505\n",
      "lr: 0.0001\n",
      "epoch 34 - train loss 0.0505 - val loss 0.0505\n",
      "lr: 0.0001\n",
      "epoch 35 - train loss 0.0504 - val loss 0.0506\n",
      "lr: 1e-05\n",
      "epoch 36 - train loss 0.0492 - val loss 0.0494\n",
      "lr: 1e-05\n",
      "epoch 37 - train loss 0.0490 - val loss 0.0495\n",
      "lr: 1e-05\n",
      "epoch 38 - train loss 0.0490 - val loss 0.0494\n",
      "lr: 1e-05\n",
      "epoch 39 - train loss 0.0489 - val loss 0.0494\n",
      "lr: 1e-05\n",
      "epoch 40 - train loss 0.0489 - val loss 0.0494\n",
      "lr: 1e-05\n",
      "epoch 41 - train loss 0.0489 - val loss 0.0493\n",
      "lr: 1e-05\n",
      "epoch 42 - train loss 0.0489 - val loss 0.0494\n",
      "lr: 1e-05\n",
      "epoch 43 - train loss 0.0488 - val loss 0.0494\n",
      "lr: 1e-05\n",
      "epoch 44 - train loss 0.0488 - val loss 0.0494\n",
      "lr: 1e-05\n",
      "epoch 45 - train loss 0.0488 - val loss 0.0494\n",
      "lr: 1e-05\n",
      "epoch 46 - train loss 0.0488 - val loss 0.0493\n",
      "lr: 1e-05\n",
      "epoch 47 - train loss 0.0488 - val loss 0.0494\n",
      "lr: 1.0000000000000002e-06\n",
      "epoch 48 - train loss 0.0486 - val loss 0.0491\n",
      "lr: 1.0000000000000002e-06\n",
      "epoch 49 - train loss 0.0485 - val loss 0.0492\n",
      "lr: 1.0000000000000002e-06\n",
      "epoch 50 - train loss 0.0486 - val loss 0.0491\n",
      "lr: 1.0000000000000002e-06\n",
      "epoch 51 - train loss 0.0486 - val loss 0.0491\n",
      "lr: 1.0000000000000002e-06\n",
      "epoch 52 - train loss 0.0486 - val loss 0.0492\n",
      "lr: 1.0000000000000002e-06\n",
      "epoch 53 - train loss 0.0485 - val loss 0.0491\n",
      "lr: 1.0000000000000002e-06\n",
      "epoch 54 - train loss 0.0485 - val loss 0.0492\n",
      "lr: 1.0000000000000002e-07\n",
      "epoch 55 - train loss 0.0485 - val loss 0.0491\n",
      "lr: 1.0000000000000002e-07\n",
      "epoch 56 - train loss 0.0485 - val loss 0.0491\n",
      "lr: 1.0000000000000002e-07\n",
      "epoch 57 - train loss 0.0485 - val loss 0.0492\n",
      "lr: 1.0000000000000002e-07\n",
      "epoch 58 - train loss 0.0485 - val loss 0.0491\n",
      "lr: 1.0000000000000002e-07\n",
      "epoch 59 - train loss 0.0485 - val loss 0.0491\n",
      "lr: 1.0000000000000002e-07\n",
      "epoch 60 - train loss 0.0485 - val loss 0.0492\n",
      "lr: 1.0000000000000004e-08\n",
      "epoch 61 - train loss 0.0485 - val loss 0.0492\n",
      "lr: 1.0000000000000004e-08\n",
      "epoch 62 - train loss 0.0485 - val loss 0.0491\n",
      "lr: 1.0000000000000004e-08\n",
      "epoch 63 - train loss 0.0485 - val loss 0.0492\n",
      "lr: 1.0000000000000004e-08\n",
      "epoch 64 - train loss 0.0485 - val loss 0.0491\n",
      "lr: 1.0000000000000004e-08\n",
      "epoch 65 - train loss 0.0485 - val loss 0.0492\n",
      "lr: 1.0000000000000004e-08\n",
      "epoch 66 - train loss 0.0485 - val loss 0.0492\n",
      "lr: 1.0000000000000004e-08\n",
      "epoch 67 - train loss 0.0485 - val loss 0.0491\n",
      "lr: 1.0000000000000004e-08\n",
      "epoch 68 - train loss 0.0485 - val loss 0.0492\n",
      "lr: 1.0000000000000004e-08\n",
      "epoch 69 - train loss 0.0485 - val loss 0.0491\n",
      "lr: 1.0000000000000004e-08\n",
      "epoch 70 - train loss 0.0485 - val loss 0.0492\n",
      "lr: 1.0000000000000004e-08\n",
      "epoch 71 - train loss 0.0485 - val loss 0.0491\n",
      "lr: 1.0000000000000004e-08\n",
      "epoch 72 - train loss 0.0485 - val loss 0.0491\n",
      "lr: 1.0000000000000004e-08\n",
      "epoch 73 - train loss 0.0485 - val loss 0.0491\n",
      "lr: 1.0000000000000004e-08\n",
      "epoch 74 - train loss 0.0486 - val loss 0.0492\n",
      "lr: 1.0000000000000004e-08\n",
      "epoch 75 - train loss 0.0485 - val loss 0.0492\n",
      "lr: 1.0000000000000004e-08\n",
      "epoch 76 - train loss 0.0485 - val loss 0.0492\n",
      "lr: 1.0000000000000004e-08\n",
      "epoch 77 - train loss 0.0485 - val loss 0.0491\n",
      "lr: 1.0000000000000004e-08\n",
      "epoch 78 - train loss 0.0485 - val loss 0.0491\n",
      "lr: 1.0000000000000004e-08\n",
      "epoch 79 - train loss 0.0486 - val loss 0.0491\n",
      "lr: 1.0000000000000004e-08\n",
      "epoch 80 - train loss 0.0485 - val loss 0.0491\n",
      "lr: 1.0000000000000004e-08\n",
      "epoch 81 - train loss 0.0485 - val loss 0.0492\n",
      "lr: 1.0000000000000004e-08\n",
      "epoch 82 - train loss 0.0485 - val loss 0.0492\n",
      "lr: 1.0000000000000004e-08\n",
      "epoch 83 - train loss 0.0485 - val loss 0.0491\n",
      "lr: 1.0000000000000004e-08\n",
      "epoch 84 - train loss 0.0485 - val loss 0.0492\n",
      "lr: 1.0000000000000004e-08\n",
      "epoch 85 - train loss 0.0485 - val loss 0.0491\n",
      "lr: 1.0000000000000004e-08\n",
      "epoch 86 - train loss 0.0485 - val loss 0.0491\n",
      "lr: 1.0000000000000004e-08\n",
      "epoch 87 - train loss 0.0485 - val loss 0.0492\n",
      "lr: 1.0000000000000004e-08\n",
      "epoch 88 - train loss 0.0485 - val loss 0.0491\n",
      "lr: 1.0000000000000004e-08\n",
      "epoch 89 - train loss 0.0485 - val loss 0.0491\n",
      "lr: 1.0000000000000004e-08\n",
      "epoch 90 - train loss 0.0485 - val loss 0.0491\n",
      "lr: 1.0000000000000004e-08\n",
      "epoch 91 - train loss 0.0485 - val loss 0.0492\n",
      "lr: 1.0000000000000004e-08\n",
      "epoch 92 - train loss 0.0485 - val loss 0.0491\n",
      "lr: 1.0000000000000004e-08\n",
      "epoch 93 - train loss 0.0485 - val loss 0.0491\n",
      "lr: 1.0000000000000004e-08\n",
      "epoch 94 - train loss 0.0485 - val loss 0.0491\n",
      "lr: 1.0000000000000004e-08\n",
      "epoch 95 - train loss 0.0485 - val loss 0.0492\n",
      "lr: 1.0000000000000004e-08\n",
      "epoch 96 - train loss 0.0485 - val loss 0.0491\n",
      "lr: 1.0000000000000004e-08\n",
      "epoch 97 - train loss 0.0485 - val loss 0.0491\n",
      "lr: 1.0000000000000004e-08\n",
      "epoch 98 - train loss 0.0485 - val loss 0.0491\n",
      "lr: 1.0000000000000004e-08\n",
      "epoch 99 - train loss 0.0485 - val loss 0.0492\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "epochs = 100\n",
    "batch_size = 32\n",
    "PATH = \"model/trackster_graphconv_noLC\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GraphNet().to(device)\n",
    "#data = data_list.to(device)\n",
    "trainLoader = DataLoader(trainDataset, batch_size=batch_size)\n",
    "valLoader = DataLoader(valDataset, batch_size=batch_size)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, threshold=1e-4, threshold_mode='abs')\n",
    "\n",
    "train_loss_history = []\n",
    "val_loss_history = []\n",
    "model.train()\n",
    "best_loss = 1e6\n",
    "focal_loss_param = 0.4\n",
    "for epoch in range(epochs):\n",
    "    batchloss = []\n",
    "    for sample in trainLoader:\n",
    "        optimizer.zero_grad()\n",
    "        sample.to(device)\n",
    "        out = model(sample)\n",
    "#         weight = [w_true if l > 0.9 else w_false for l in sample.edge_label] # weigh edges\n",
    "#         loss = F.binary_cross_entropy(out, sample.edge_label, weight=torch.tensor(weight))\n",
    "        bce_loss = F.binary_cross_entropy(out, sample.edge_label)\n",
    "        loss = focal_loss(bce_loss, sample.edge_label, 2, focal_loss_param)\n",
    "#         print(f\"out {out}\")\n",
    "#         print(f\"label {sample.edge_label}\")\n",
    "#         print(f\"loss {loss}\")\n",
    "        batchloss.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    for param_group in optimizer.param_groups:\n",
    "        print(f\"lr: {param_group['lr']}\")\n",
    "    batch_loss_mean = np.mean(batchloss)\n",
    "    train_loss_history.append(batch_loss_mean)\n",
    "    if(batch_loss_mean < best_loss):\n",
    "        # Save model so as not to repeat the training\n",
    "        torch.save(model.state_dict(), PATH +\".pt\")\n",
    "    with torch.set_grad_enabled( False ):\n",
    "        batchloss = []\n",
    "        for sample in valLoader:\n",
    "            sample.to(device)\n",
    "            out = model(sample)\n",
    "            #val_loss = F.binary_cross_entropy_with_logits(out, sample.edge_label)\n",
    "            val_bce = F.binary_cross_entropy(out, sample.edge_label)\n",
    "            val_loss = focal_loss(val_bce, sample.edge_label, 2, focal_loss_param)\n",
    "            batchloss.append(val_loss.item())\n",
    "            \n",
    "    val_loss_history.append(np.mean(batchloss))\n",
    "    scheduler.step(val_loss_history[-1])\n",
    "    print(f\"epoch {epoch} - train loss {train_loss_history[-1]:.4f} - val loss {val_loss_history[-1]:.4f}\")\n",
    "    \n",
    "# Save model so as not to repeat the training\n",
    "\n",
    "torch.save(model.state_dict(), PATH +\"_final.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1332ee81",
   "metadata": {},
   "outputs": [],
   "source": [
    "xaxis = range(1, epochs+1)\n",
    "plt.plot(xaxis, train_loss_history, label='train')\n",
    "plt.plot(xaxis, val_loss_history, label='val')\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "#plt.xticks(range(epochs), range(1, epochs+1))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18058ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20641f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4129d72d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['featureExtractor.conv1.weight', 'featureExtractor.conv1.bias', 'featureExtractor.conv2.weight', 'featureExtractor.conv2.bias', 'featureExtractor.conv3.weight', 'featureExtractor.conv3.bias', 'featureExtractor.conv4.weight', 'featureExtractor.conv4.bias', 'inputnetwork.0.weight', 'inputnetwork.0.bias', 'inputnetwork.1.weight', 'inputnetwork.1.bias', 'inputnetwork.1.running_mean', 'inputnetwork.1.running_var', 'inputnetwork.1.num_batches_tracked', 'inputnetwork.3.weight', 'inputnetwork.3.bias', 'graphconv.nn.0.weight', 'graphconv.nn.0.bias', 'graphconv.nn.3.weight', 'graphconv.nn.3.bias', 'edgenetwork.0.weight', 'edgenetwork.0.bias', 'edgenetwork.3.weight', 'edgenetwork.3.bias', 'edgenetwork.6.weight', 'edgenetwork.6.bias'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load(PATH).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19843531",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd0d85b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphNet(\n",
       "  (featureExtractor): Net(\n",
       "    (conv1): Conv1d(1, 4, kernel_size=(3,), stride=(1,))\n",
       "    (conv2): Conv1d(4, 4, kernel_size=(3,), stride=(3,))\n",
       "    (conv3): Conv1d(4, 4, kernel_size=(3,), stride=(3,))\n",
       "    (conv4): Conv1d(4, 8, kernel_size=(3,), stride=(3,))\n",
       "    (pool): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (inputnetwork): Sequential(\n",
       "    (0): Linear(in_features=20, out_features=128, bias=True)\n",
       "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ELU(alpha=1.0)\n",
       "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (4): ReLU()\n",
       "  )\n",
       "  (graphconv): EdgeConv(nn=Sequential(\n",
       "    (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (4): ReLU()\n",
       "  ))\n",
       "  (edgenetwork): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.2, inplace=False)\n",
       "    (6): Linear(in_features=128, out_features=1, bias=True)\n",
       "    (7): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_test = GraphNet()\n",
    "model_test.load_state_dict(torch.load(PATH))\n",
    "model_test.eval()\n",
    "model_test.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9bb5f18e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "167905"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "90fda9bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testDataset[0][-1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9cab8bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_and_get_data(data_list, ev):\n",
    "    data_list_ev = data_list[ev]\n",
    "    x_np = data_list_ev[0]\n",
    "    x_coord_slice = x_np[:, [0,1,2]]\n",
    "    x_rest_slice = x_np[:, [9,10,11]]\n",
    "    x_en_lay_ev = data_list_ev[-1]\n",
    "    mean = []\n",
    "    std = []\n",
    "    scaler=StandardScaler()\n",
    "    scaler.fit(x_coord_slice)\n",
    "    x_coord_norm = scaler.transform(x_coord_slice)\n",
    "    mean.append(scaler.mean_)\n",
    "    std.append(scaler.scale_)\n",
    "    \n",
    "    mean.append(np.zeros(6)) # for the unnormalized features\n",
    "    std.append(np.ones(6))\n",
    "    \n",
    "    scaler.fit(x_rest_slice)\n",
    "    x_rest_norm = scaler.transform(x_rest_slice)\n",
    "    mean.append(scaler.mean_)\n",
    "    std.append(scaler.scale_)\n",
    "    \n",
    "    mean = np.concatenate(mean, axis=-1)\n",
    "    std = np.concatenate(std, axis=-1)\n",
    "    \n",
    "    x_ev = torch.from_numpy(np.concatenate((x_coord_norm, x_np[:,[3,4,5,6,7,8]], x_rest_norm), axis=1))\n",
    "    edge_label = torch.from_numpy(data_list_ev[1])\n",
    "    edge_index = torch.from_numpy(data_list_ev[2])\n",
    "    data = Data(x=x_ev, num_nodes=torch.tensor(x_ev.shape[0]), edge_index=edge_index, edge_label=edge_label, en_hgcal_layers = x_en_lay_ev)\n",
    "    \n",
    "    return data, mean, std\n",
    "\n",
    "testData = []\n",
    "for ev in range(len(testDataset)):\n",
    "    data, mean, std = normalize_and_get_data(testDataset, ev)\n",
    "    testData.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665b1d07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "95170e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded\n",
      "Accuracy in test data 61.4240 %\n",
      "Confusion matrix [[441057  68675]\n",
      " [441040 367754]]\n"
     ]
    }
   ],
   "source": [
    "#testDataset = torch.load(\"/eos/user/w/wredjeb/SWAN_projects/GraphSC/HackathonLinking/dataProcessed/dataTest.pt\")\n",
    "classification_threshold = 0.7\n",
    "def getAccuracy(y_true, y_prob):\n",
    "    assert y_true.ndim == 1 and y_true.size() == y_prob.size()\n",
    "    y_prob = y_prob > classification_threshold\n",
    "    return (y_true == y_prob).sum().item() / y_true.size(0)\n",
    "\n",
    "testLoader = DataLoader(testData, batch_size=batch_size)\n",
    "print(\"loaded\")\n",
    "\n",
    "predictions = []\n",
    "truth = []\n",
    "accuracies = []\n",
    "\n",
    "for sample in testLoader:\n",
    "    sample.to(device)\n",
    "    out = model_test(sample)\n",
    "    acc = getAccuracy(sample.edge_label, out)\n",
    "    accuracies.append(acc)\n",
    "    y_test = out > classification_threshold\n",
    "    predictions.append(y_test.cpu().numpy())\n",
    "    truth.append(sample.edge_label.cpu().numpy())\n",
    "    \n",
    "cf_matrix = confusion_matrix(np.concatenate(truth), np.concatenate(predictions))\n",
    "#cf_matrix = confusion_matrix(sample.edge_label.detach().numpy(), y_test.detach().numpy())\n",
    "print(f\"Accuracy in test data {np.mean(accuracies)*100:.4f} %\")\n",
    "print(f\"Confusion matrix {cf_matrix}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f821845c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphNet(\n",
       "  (featureExtractor): Net(\n",
       "    (conv1): Conv1d(1, 4, kernel_size=(3,), stride=(1,))\n",
       "    (conv2): Conv1d(4, 4, kernel_size=(3,), stride=(3,))\n",
       "    (conv3): Conv1d(4, 4, kernel_size=(3,), stride=(3,))\n",
       "    (conv4): Conv1d(4, 8, kernel_size=(3,), stride=(3,))\n",
       "    (pool): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (inputnetwork): Sequential(\n",
       "    (0): Linear(in_features=20, out_features=128, bias=True)\n",
       "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ELU(alpha=1.0)\n",
       "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (4): ReLU()\n",
       "  )\n",
       "  (graphconv): EdgeConv(nn=Sequential(\n",
       "    (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (4): ReLU()\n",
       "  ))\n",
       "  (edgenetwork): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.2, inplace=False)\n",
       "    (6): Linear(in_features=128, out_features=1, bias=True)\n",
       "    (7): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0e53e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b9107fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying to accumulate connected tracksters in superclusters\n",
    "eventLoader = DataLoader(testData, batch_size=1)\n",
    "events=0\n",
    "edges_event = []\n",
    "preds_event = []\n",
    "nodes_event = []\n",
    "events = 0\n",
    "for sample in eventLoader:\n",
    "    events+=1\n",
    "    sample.to(\"cpu\")\n",
    "    model.to(\"cpu\")\n",
    "    outGraph = model(sample, \"cpu\")\n",
    "    edges_event.append(sample.edge_index)\n",
    "    preds_event.append(outGraph)\n",
    "    nodes_event.append(len(sample.x))\n",
    "    #print(len(sample.edge_index[0]))\n",
    "    #print(len(outGraph))\n",
    "    if events > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70403712",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f295f5d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.33450762 0.05208468]\n",
      " [0.33449473 0.27891297]]\n",
      "\n",
      "Accuracy : 61.3421%\n",
      "Precision : 84.2643\n",
      "Recall : 45.4694% -> positive edges correctly classified\n",
      "Correctly classifying 86.5272% of all negative edges\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = cf_matrix.ravel()\n",
    "tot = tn+fp+fn+tp\n",
    "# normalized to total edges in test dataset\n",
    "print(f\"{cf_matrix/tot}\\n\")\n",
    "print(f\"Accuracy : {(tp+tn)/tot*100:.4f}%\")\n",
    "print(f\"Precision : {tp/(tp+fp)*100:.4f}\")\n",
    "print(f\"Recall : {tp/(tp+fn)*100:.4f}% -> positive edges correctly classified\")\n",
    "print(f\"Correctly classifying {tn/(tn+fp)*100:.4f}% of all negative edges\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "31da276e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TN: 0.33450762442302995, FP: 0.05208467637346552, FN: 0.33449473123776097, TP: 0.27891296796574355\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7f5b15d65640>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 540x540 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"TN: {tn/tot}, FP: {fp/tot}, FN: {fn/tot}, TP: {tp/tot}\")\n",
    "fig, px = plt.subplots(figsize=(7.5, 7.5))\n",
    "px.set_xlabel(\"predicted\")\n",
    "px.set_ylabel(\"true\")\n",
    "cax = px.matshow(cf_matrix/(tn+fp+fn+tp))\n",
    "fig.colorbar(cax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd8ee7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52a4d3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48c62c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
